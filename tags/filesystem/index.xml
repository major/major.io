<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>filesystem on Major Hayden ðŸ¤ </title><link>https://major.io/tags/filesystem/</link><description>Recent content in filesystem on Major Hayden ðŸ¤ </description><generator>Hugo -- gohugo.io</generator><copyright>&lt;a href="https://creativecommons.org/licenses/by-sa/2.0/" target="_blank" rel="noopener">CC BY-SA 2.0&lt;/a></copyright><lastBuildDate>Tue, 29 Jul 2014 13:05:54 +0000</lastBuildDate><atom:link href="https://major.io/tags/filesystem/index.xml" rel="self" type="application/rss+xml"/><item><title>Adventures in live booting Linux distributions</title><link>https://major.io/2014/07/29/adventures-in-live-booting-linux-distributions/</link><pubDate>Tue, 29 Jul 2014 13:05:54 +0000</pubDate><guid>https://major.io/2014/07/29/adventures-in-live-booting-linux-distributions/</guid><description>We&amp;rsquo;re all familiar with live booting Linux distributions. Almost every Linux distribution under the sun has a method for making live CD&amp;rsquo;s, writing live USB sticks, or booting live images over the network. The primary use case for some distributions is on a live medium (like KNOPPIX).
However, I embarked on an adventure to look at live booting Linux for a different use case. Sure, many live environments are used for demonstrations or installations - temporary activities for a desktop or a laptop.</description></item><item><title>Dual-primary DRBD with OCFS2</title><link>https://major.io/2011/02/13/dual-primary-drbd-with-ocfs2/</link><pubDate>Mon, 14 Feb 2011 02:12:58 +0000</pubDate><guid>https://major.io/2011/02/13/dual-primary-drbd-with-ocfs2/</guid><description>As promised in one of my previous posts about dual-primary DRBD and OCFS2, I&amp;rsquo;ve compiled a step-by-step guide for Fedora. These instructions should be somewhat close to what you would use on CentOS or Red Hat Enterprise Linux. However, CentOS and Red Hat don&amp;rsquo;t provide some of the packages needed, so you will need to use other software repositories like RPMFusion or EPEL.
In this guide, I&amp;rsquo;ll be using two Fedora 14 instances in the Rackspace Cloud with separate public and private networks.</description></item><item><title>Keep web servers in sync with DRBD and OCFS2</title><link>https://major.io/2010/12/02/keep-web-servers-in-sync-with-drbd-and-ocfs2/</link><pubDate>Fri, 03 Dec 2010 02:01:12 +0000</pubDate><guid>https://major.io/2010/12/02/keep-web-servers-in-sync-with-drbd-and-ocfs2/</guid><description>The guide to redundant cloud hosting that I wrote recently will need some adjustments as I&amp;rsquo;ve fallen hard for the performance and reliability of DRBD and OCFS2. As a few of my sites were gaining in popularity, I noticed that GlusterFS simply couldn&amp;rsquo;t keep up. High I/O latency and broken replication threw a wrench into my love affair with GlusterFS and I knew there had to be a better option.</description></item><item><title>Switching from GlusterFS to DRBD and OCFS2</title><link>https://major.io/2010/11/10/switching-from-glusterfs-to-drbd-and-ocfs2/</link><pubDate>Wed, 10 Nov 2010 13:55:50 +0000</pubDate><guid>https://major.io/2010/11/10/switching-from-glusterfs-to-drbd-and-ocfs2/</guid><description>As my uptime reports have shown, and as some of you have reported, my blog&amp;rsquo;s load time has increased steadily over the past few weeks. It turns out that one of my VM&amp;rsquo;s was on a physical machine that had some trouble and I was reaching a point where GlusterFS&amp;rsquo;s replicate functionality couldn&amp;rsquo;t meet my performance needs.
Instead of using GlusterFS as I had before in my redundant cloud hosting guide, I decided to use DRBD in dual-primary mode with OCFS2 as the clustering filesystem on top of it.</description></item><item><title>GlusterFS on the cheap with Rackspaceâ€™s Cloud Servers or Slicehost</title><link>https://major.io/2010/05/27/glusterfs-on-the-cheap-with-rackspaces-cloud-servers-or-slicehost/</link><pubDate>Fri, 28 May 2010 00:34:10 +0000</pubDate><guid>https://major.io/2010/05/27/glusterfs-on-the-cheap-with-rackspaces-cloud-servers-or-slicehost/</guid><description>NOTE:This post is out of date and is relevant only for GlusterFS 2.x.
*High availability is certainly not a new concept, but if there&amp;rsquo;s one thing that frustrates me with high availability VM setups, it&amp;rsquo;s storage. If you don&amp;rsquo;t mind going active-passive, you can set up DRBD, toss your favorite filesystem on it, and you&amp;rsquo;re all set.If you want to go active-active, or if you want multiple nodes active at the same time, you need to use a clustered filesystem like GFS2, OCFS2 or Lustre.</description></item><item><title>ext3_dx_add_entry: Directory index full!</title><link>https://major.io/2008/10/13/ext3_dx_add_entry-directory-index-full/</link><pubDate>Mon, 13 Oct 2008 17:00:51 +0000</pubDate><guid>https://major.io/2008/10/13/ext3_dx_add_entry-directory-index-full/</guid><description>I found a server last week that was having severe issues with disk I/O to the point where most operations were taking many minutes to complete. The server wasn&amp;rsquo;t under much load, but a quick run of dmesg threw quite a bit of these lines out onto the screen:
EXT3-fs warning (device sda5): ext3_dx_add_entry: Directory index full!
After a thorough amount of searching, I couldn&amp;rsquo;t find out what the error actually meant.</description></item><item><title>What is the difference between file data and metadata?</title><link>https://major.io/2008/03/12/what-is-the-difference-between-file-data-and-metadata/</link><pubDate>Wed, 12 Mar 2008 18:01:59 +0000</pubDate><guid>https://major.io/2008/03/12/what-is-the-difference-between-file-data-and-metadata/</guid><description>Just in case some of you out there enjoy nomenclature and theory behind Linux filesystems, here&amp;rsquo;s some things to keep in mind. The modification time (mtime) of a file describes when the actual data blocks that hold the file changed. The changed time (ctime) of a file describes when the metadata was last changed.
Also, metadata is stored within a different location than the data blocks. The metadata fits in the inode while the file&amp;rsquo;s data goes within data blocks.</description></item><item><title>EXT3-fs error (device hda3) in start_transaction: Journal has aborted</title><link>https://major.io/2007/11/20/ext3-fs-error-device-hda3-in-start_transaction-journal-has-aborted/</link><pubDate>Tue, 20 Nov 2007 18:23:40 +0000</pubDate><guid>https://major.io/2007/11/20/ext3-fs-error-device-hda3-in-start_transaction-journal-has-aborted/</guid><description>If your system abruptly loses power, or if a RAID card is beginning to fail, you might see an ominous message like this within your logs:
Basically, the system is telling you that it&amp;rsquo;s detected a filesystem/journal mismatch, and it can&amp;rsquo;t utilize the journal any longer. When this situation pops up, the filesystem gets mounted read-only almost immediately. To fix the situation, you can remount the partition as ext2 (if it isn&amp;rsquo;t your active root partition), or you can commence the repair operations.</description></item></channel></rss>