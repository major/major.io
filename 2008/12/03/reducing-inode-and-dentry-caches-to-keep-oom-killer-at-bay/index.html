<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=author content="Major Hayden"><meta name=description content="When it comes to frustrating parts of the Linux kernel, OOM killer takes the cake. If it finds that applications are using too much memory on the server, it will kill process abruptly to free up memory for the system to use. I spent much of this week wrestling with a server that was in the clutches of OOM killer.
There are a few processes on the server that keep it fairly busy."><meta name=keywords content=",emergency,kernel"><meta name=robots content="noodp"><meta name=theme-color content><link rel=canonical href=https://major.io/2008/12/03/reducing-inode-and-dentry-caches-to-keep-oom-killer-at-bay/><title>Reducing inode and dentry caches to keep OOM killer at bay :: Major Hayden ü§† ‚Äî Words of wisdom from a social nerd</title><link href=https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.min.css rel=stylesheet type=text/css><link rel=stylesheet href=../../../../main.89fa80e2143f71bd5c96a7c94e531dec3276a367e22f87e74a76026ab64680bf.css><link rel=apple-touch-icon sizes=180x180 href=../../../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../../../favicon-16x16.png><link rel=manifest href=../../../../site.webmanifest><link rel=mask-icon href=../../../../safari-pinned-tab.svg color=#252627><link rel="shortcut icon" href=../../../../favicon.ico><meta name=msapplication-TileColor content="#252627"><meta name=theme-color content="#252627"><meta itemprop=name content="Reducing inode and dentry caches to keep OOM killer at bay"><meta itemprop=description content="When it comes to frustrating parts of the Linux kernel, OOM killer takes the cake. If it finds that applications are using too much memory on the server, it will kill process abruptly to free up memory for the system to use. I spent much of this week wrestling with a server that was in the clutches of OOM killer.
There are a few processes on the server that keep it fairly busy."><meta itemprop=datePublished content="2008-12-04T00:44:20+00:00"><meta itemprop=dateModified content="2008-12-04T00:44:20+00:00"><meta itemprop=wordCount content="577"><meta itemprop=image content="https://major.io"><meta itemprop=keywords content="emergency,kernel,"><meta property="article:section" content="Blog Posts"><meta property="article:published_time" content="2008-12-04 00:44:20 +0000 UTC"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Reducing inode and dentry caches to keep OOM killer at bay :: Major Hayden ü§†"><meta name=twitter:description content><meta name=twitter:site content="https://major.io"><meta name=twitter:creator content="Major Hayden"><meta name=twitter:image content><style type=text/css>html{letter-spacing:unset}</style></head><body class=dark-theme><div class=container><header class=header><span class=header__inner><a href=../../../../ style=text-decoration:none><div class=logo><span class=logo__mark>></span>
<span class=logo__text>$ echo major.io</span>
<span class=logo__cursor style=visibility:hidden></span></div></a><span class=header__right><nav class=menu><ul class=menu__inner><li><a href=../../../../ham-radio-faq>hamradio</a></li><li><a href=../../../../icanhazip-com-faq>icanhazip</a></li><li><a href=../../../../posts/>posts</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></span><span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M22 41C32.4934 41 41 32.4934 41 22 41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span></span></span></header><div class=content><main class=post><div class=post-info></p></div><article><h2 class=post-title><a href=https://major.io/2008/12/03/reducing-inode-and-dentry-caches-to-keep-oom-killer-at-bay/>Reducing inode and dentry caches to keep OOM killer at bay</a></h2><div class=post-content><p>When it comes to frustrating parts of the Linux kernel, <a href=http://linux-mm.org/OOM_Killer>OOM killer</a> takes the cake. If it finds that applications are using too much memory on the server, it will kill process abruptly to free up memory for the system to use. I spent much of this week wrestling with a server that was in the clutches of OOM killer.</p><p>There are a few processes on the server that keep it fairly busy. Two of the processes are vital to the server&rsquo;s operation ‚Äì if they are stopped, lots of work is required to get them running properly again. I found that a certain java process was being killed by OOM killer regularly, and another perl process was being killed occasionally.</p><p>Naturally, my disdain for java made me think that the java process was the source of the issue. The process was configured to use a small amount of RAM, so it was ruled out. The other perl process used even less memory, so it was ruled out as well. When I checked the sysstat data with sar, I found that the server was only using about 2-3GB out of 4GB of physical memory at the time when OOM killer was started. <em>At this point, I was utterly perplexed.</em></p><p>I polled some folks around the office and gathered some ideas. After putting some ideas together, I found that the server was actually caching too much data in the <code>ext3_inode_cache</code> and <code>dentry_cache</code>. These caches hold recently accessed files and directories on the server, and they&rsquo;re purged as the files and directories become stale. Since the operations on the server read and write large amounts of data locally and via NFS, I knew these caches had to be gigantic. If you want to check your own caches, you can use the <code>slabtop</code> command. For those who like things more difficult, you can also <code>cat</code> the contents of <code>/proc/slabinfo</code> and grep for the caches that are important to you.</p><p>An immense amount of Googling revealed very little, but I discovered a <a href=http://www.linuxinsight.com/proc_sys_vm_drop_caches.html>dirty hack</a> to fix the issue <strong>(don&rsquo;t run this yet)</strong>:</p><p><strong>There are huge consequences to dumping these caches and running <code>sync</code>.</strong> If you are writing data at the time you run these commands, you&rsquo;ll actually be dumping the data out of the filesystem cache before it reaches the disk, which could lead to very bad things.</p><p>While discussing the issue with a coworker, he <a href=http://www.linuxinsight.com/proc_sys_vm_vfs_cache_pressure.html>found a different method</a> for correcting the issue that was <strong>much</strong> safer. You can echo values into <strong>/proc/sys/vm/vfs_cache_pressure</strong> to tell the kernel what priority it should take when clearing out the inode/dentry caches. LinuxInsight explains the range of values well:</p><blockquote><p>At the default value of vfs_cache_pressure = 100 the kernel will attempt to reclaim dentries and inodes at a ‚Äúfair‚Äù rate with respect to pagecache and swapcache reclaim. Decreasing vfs_cache_pressure causes the kernel to prefer to retain dentry and inode caches. Increasing vfs_cache_pressure beyond 100 causes the kernel to prefer to reclaim dentries and inodes.</p></blockquote><p>In short, values less than 100 won&rsquo;t reduce the caches very much as all. Values over 100 will signal to the kernel that you want to clear out the caches at a higher priority. I found that no matter what value you use, the kernel clears the caches at a slow rate. I&rsquo;ve been using a value of 10000 on the server I talked about earlier in the article, and it has kept the caches down to a reasonable level.</p></div></article><hr><div class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7" y2="7"/></svg><span class=tag><a href=https://major.io/tags/emergency/>emergency</a></span>
<span class=tag><a href=https://major.io/tags/kernel/>kernel</a></span></p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-folder meta-icon"><path d="M22 19a2 2 0 01-2 2H4a2 2 0 01-2-2V5a2 2 0 012-2h5l2 3h9a2 2 0 012 2z"/></svg><span class=tag><a href=https://major.io/categories/blog-posts/>Blog Posts</a></span></p></div></main></div><footer class=footer><div class=footer__inner><div class=footer__content><span>&copy; 2021</span>
<span><a href=https://major.io>Major Hayden</a></span>
<span><a href=https://creativecommons.org/licenses/by-sa/2.0/ target=_blank rel=noopener>CC BY-SA 2.0</a></span><span><a href=https://major.io/posts/index.xml target=_blank title=rss><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 20 20" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></span></div></div><div class=footer__inner><div class=footer__content><span>Powered by <a href=http://gohugo.io>Hugo</a></span>
<span>Made with &#10084; by <a href=https://github.com/rhazdon>Djordje Atlialp</a></span></div></div></footer></div><script type=text/javascript src=../../../../bundle.min.9dd6c4fd1eb55000d257db1269676cdb26bfcc9ab1b1dc8885a54f94b97fa86e6d72e435907d76f8662e0f65472e78ab8ad69c36624d8d4a96c04c42e029d957.js integrity="sha512-ndbE/R61UADSV9sSaWds2ya/zJqxsdyIhaVPlLl/qG5tcuQ1kH12+GYuD2VHLniritacNmJNjUqWwExC4CnZVw=="></script></body></html>