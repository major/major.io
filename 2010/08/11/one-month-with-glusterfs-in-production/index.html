<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=author content="Major Hayden"><meta name=description content="As many of you might have noticed from my previous GlusterFS blog post and my various tweets, I&amp;rsquo;ve been working with GlusterFS in production for my personal hosting needs for just over a month. I&amp;rsquo;ve also been learning quite a bit from some of the folks in the #gluster channel on Freenode. On a few occasions I&amp;rsquo;ve even been able to help out with some configuration problems from other users."><meta name=keywords content=",glusterfs,linux,network,sysadmin,web,wordpress"><meta name=robots content="noodp"><meta name=theme-color content><link rel=canonical href=https://major.io/2010/08/11/one-month-with-glusterfs-in-production/><title>One month with GlusterFS in production :: Major Hayden ðŸ¤  â€” Words of wisdom from a social nerd</title><link href=https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.min.css rel=stylesheet type=text/css><link rel=stylesheet href=../../../../main.89fa80e2143f71bd5c96a7c94e531dec3276a367e22f87e74a76026ab64680bf.css><link rel=apple-touch-icon sizes=180x180 href=../../../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../../../favicon-16x16.png><link rel=manifest href=../../../../site.webmanifest><link rel=mask-icon href=../../../../safari-pinned-tab.svg color=#252627><link rel="shortcut icon" href=../../../../favicon.ico><meta name=msapplication-TileColor content="#252627"><meta name=theme-color content="#252627"><meta itemprop=name content="One month with GlusterFS in production"><meta itemprop=description content="As many of you might have noticed from my previous GlusterFS blog post and my various tweets, I&rsquo;ve been working with GlusterFS in production for my personal hosting needs for just over a month. I&rsquo;ve also been learning quite a bit from some of the folks in the #gluster channel on Freenode. On a few occasions I&rsquo;ve even been able to help out with some configuration problems from other users."><meta itemprop=datePublished content="2010-08-11T13:29:02+00:00"><meta itemprop=dateModified content="2010-08-11T13:29:02+00:00"><meta itemprop=wordCount content="1153"><meta itemprop=image content="https://major.io"><meta itemprop=keywords content="glusterfs,linux,network,sysadmin,web,wordpress,"><meta property="article:section" content="Blog Posts"><meta property="article:published_time" content="2010-08-11 13:29:02 +0000 UTC"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="One month with GlusterFS in production :: Major Hayden ðŸ¤ "><meta name=twitter:description content><meta name=twitter:site content="https://major.io"><meta name=twitter:creator content="Major Hayden"><meta name=twitter:image content><style type=text/css>html{letter-spacing:unset}</style></head><body><div class=container><header class=header><span class=header__inner><a href=../../../../ style=text-decoration:none><div class=logo><span class=logo__mark>></span>
<span class=logo__text>$ echo major.io</span>
<span class=logo__cursor style=visibility:hidden></span></div></a><span class=header__right><nav class=menu><ul class=menu__inner><li><a href=../../../../ham-radio-faq>hamradio</a></li><li><a href=../../../../icanhazip-com-faq>icanhazip</a></li><li><a href=../../../../posts/>posts</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></span><span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M22 41c10.4934.0 19-8.5066 19-19C41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span></span></span></header><div class=content><main class=post><div class=post-info></p></div><article><h2 class=post-title><a href=https://major.io/2010/08/11/one-month-with-glusterfs-in-production/>One month with GlusterFS in production</a></h2><div class=post-content><p>As many of you might have noticed from my <a href=../../../../2010/05/27/glusterfs-on-the-cheap-with-rackspaces-cloud-servers-or-slicehost/>previous GlusterFS blog post</a> and my <a href=http://twitter.com/rackerhacker>various tweets</a>, I&rsquo;ve been working with GlusterFS in production for my personal hosting needs for just over a month. I&rsquo;ve also been learning quite a bit from some of the folks in the <a href="http://java.freenode.net/index.php?channel=gluster">#gluster</a> channel on <a href=http://freenode.net/>Freenode</a>. On a few occasions I&rsquo;ve even been able to help out with some configuration problems from other users.</p><p>There has been quite a bit of interest in GlusterFS as of late and I&rsquo;ve been inundated with questions from coworkers, other system administrators and developers. Most folks want to know about its reliability and performance in demanding production environments. I&rsquo;ll try to do my best to cover the big points in this post.</p><p><strong>First off, here&rsquo;s now I&rsquo;m using it in production:</strong> I have two web nodes that keep content in sync for various web sites. They each run a GlusterFS server instance and they also mount their GlusterFS share. I&rsquo;m using the <a href=http://www.gluster.com/community/documentation/index.php/Translators/cluster/replicate>replicate translator</a> to keep both web nodes in sync with client side replication.</p><p>Here are my impressions after a month:</p><p><strong>I/O speed is often tied heavily to network throughput</strong></p><p>This one may seem obvious, but it&rsquo;s not always true in all environments. If you deal with a lot of small files like I do, a 40mbit/sec link between the Xen guests is plenty. Adding extra throughput didn&rsquo;t add any performance to my servers. However, if you wrangle large files on your servers regularly, you may want to consider higher throughput links between your servers. I was able to push just under 900mbit/sec by using dd to create a large file within a GlusterFS mount.</p><p><strong>Network and I/O latency are big factors for small file performance</strong></p><p>If you have a busy network and the latency creeps up from time to time, you&rsquo;ll find that your small file performance will drop significantly (especially with the replicate translator). Without getting too nerdy (you&rsquo;re welcome to read the <a href=http://ftp.zresearch.com/pub/gluster/glusterfs/doc/afr.pdf>technical document on replication</a>), replication is an intensive process. When a file is accessed, the client goes around to each server node to ensure that it not only has a copy of the file being read, but that it has the <em>correct</em> copy. If a server didn&rsquo;t save a copy of a file (due to disk failure or the server being offline when the file was written), it has to be synced across the network from one of the good nodes.</p><p>When you write files on replicated servers, the client has to roll through the same process first. Once that&rsquo;s done, it has to lock the file, write to the change log, then do the write operation, drop the change log entries, and then unlock the file. All of those operations must be done on <em>all of the servers</em>. High latency networks will wreak havoc on this process and cause it to take longer than it should.</p><p>It&rsquo;s quite obvious that if you have a fast, low-latency network between your servers, slow disks can still be a problem. If the client is waiting on the server nodes' disks to write data, the read and write performance will suffer. I&rsquo;ve tested this in environments with fast networks and very busy RAID arrays. Even if the network was very underutilized, slow disks could cut performance drastically.</p><p><strong>Monitoring GlusterFS isn&rsquo;t easy</strong></p><p>When the client has communication problems with the server nodes, some weird things can happen. I&rsquo;ve seen situations where the client loses connections to the servers (see the next section on reliability) and the client mount simply hangs. In other situations, the client has been knocked offline entirely and the process is missing from the process tree by the time I logged in. Your monitoring will need to ensure that the mount is active and is responding in a timely fashion.</p><p>There&rsquo;s a <a href=http://www.sirgroane.net/2010/04/monitoring-gluster-with-nagios/>handy script</a> which allows you to monitor GlusterFS mounts via nagios that Ian Rogers put together. Also, you can get some historical data with <a href=http://github.com/acrollet/munin-glusterfs>acrollet&rsquo;s munin-glusterfs plugin</a>.</p><p><strong>GlusterFS 3.x is pretty reliable</strong></p><p>When I first started working with GlusterFS, I was using a version from the 2.x tree. The Fedora package maintainer hadn&rsquo;t updated the package in quite some time, but I figured it should work well enough for my needs. I found that the small file performance was lacking and the nodes often had communication issues when many files were being accessed or written simultaneously. This improved when I built my own RPMs of 3.0.4 (and later 3.0.5) and began using those instead.</p><p>I did some failure testing by hard cycling the server and client nodes and found some interesting results. First off, abruptly pulling clients had no effects on the other clients or the server nodes. The connection eventually timed out and the servers logged the timeout as expected.</p><p>Abruptly pulling servers led to some mixed results. In the 2.x branch, I saw client hangs and timeouts when I abruptly removed a server. This appears to be mostly corrected in the 3.x branch. If you&rsquo;re using replicate, it&rsquo;s important to keep in mind that the first server volume listed in your client&rsquo;s volume file is the one that will be coordinating the file and directory locking. Should that one fall offline quickly, you&rsquo;ll see a hiccup in performance for a brief moment and the next server will be used for coordinating the locking. When your original server comes back up, the locking coordination will shift back.</p><p><strong>Conclusion</strong></p><p>I&rsquo;m really impressed with how much GlusterFS can do with the simplicity of how it operates. Sure, you can get better performance and more features (sometimes) from something like Lustre or GFS2, but the amount of work required to stand up that kind of cluster isn&rsquo;t trivial. GlusterFS really only requires that your kernel have FUSE support (it&rsquo;s been in mainline kernels since 2.6.14).</p><p>There are some things that GlusterFS really needs in order to succeed:</p><ul><li><strong>Documentation</strong> - The current documentation is often out of date and confusing. I&rsquo;ve even found instances where the documentation contradicts itself. While there are some good technical documents about the design of some translators, they really ought to do some more work there.</li><li><strong>Statistics gathering</strong> - It&rsquo;s very difficult to find out what GlusterFS is doing and where it can be optimized. Profiling your environment to find your bottlenecks is nearly impossible with the 2.x and 3.x branches. It doesn&rsquo;t make it easier when some of the performance translators actually decrease performance.</li><li><strong>Community involvement</strong> - This ties back into the documentation part a little, but it would be nice to see more participation from Gluster employees on IRC and via the mailing lists. They&rsquo;re a little better with mailing list responses than other companies I&rsquo;ve seen, but there is still room for improvement.</li></ul><p>If you&rsquo;re considering GlusterFS for your servers but you still have more questions, feel free to leave a comment or find me on Freenode (I&rsquo;m &lsquo;rackerhacker&rsquo;).</p></div></article><hr><div class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7" y2="7"/></svg><span class=tag><a href=https://major.io/tags/glusterfs/>glusterfs</a></span>
<span class=tag><a href=https://major.io/tags/linux/>linux</a></span>
<span class=tag><a href=https://major.io/tags/network/>network</a></span>
<span class=tag><a href=https://major.io/tags/sysadmin/>sysadmin</a></span>
<span class=tag><a href=https://major.io/tags/web/>web</a></span>
<span class=tag><a href=https://major.io/tags/wordpress/>wordpress</a></span></p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-folder meta-icon"><path d="M22 19a2 2 0 01-2 2H4a2 2 0 01-2-2V5a2 2 0 012-2h5l2 3h9a2 2 0 012 2z"/></svg><span class=tag><a href=https://major.io/categories/blog-posts/>Blog Posts</a></span></p></div></main></div><footer class=footer><div class=footer__inner><div class=footer__content><span>&copy; 2021</span>
<span><a href=https://major.io>Major Hayden</a></span>
<span><a href=https://creativecommons.org/licenses/by-sa/2.0/ target=_blank rel=noopener>CC BY-SA 2.0</a></span><span><a href=https://major.io/posts/index.xml target=_blank title=rss><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 20 20" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></span></div></div><div class=footer__inner><div class=footer__content><span>Powered by <a href=http://gohugo.io>Hugo</a></span>
<span>Made with &#10084; by <a href=https://github.com/rhazdon>Djordje Atlialp</a></span></div></div></footer></div><script type=text/javascript src=../../../../bundle.min.e9f93b80e78a22e6f04cbb5f73e0f9c4ba60ff73a2a0ef85965c688f93dd1f2722a282e30e485603e4c65b1b346720e35f213435ec5556e196a97a68d097c80f.js integrity="sha512-6fk7gOeKIubwTLtfc+D5xLpg/3OioO+Fllxoj5PdHyciooLjDkhWA+TGWxs0ZyDjXyE0NexVVuGWqXpo0JfIDw=="></script></body></html>